{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1808590,"sourceType":"datasetVersion","datasetId":989445}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom nltk.tokenize import word_tokenize\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.utils import resample\nfrom sklearn.svm import  LinearSVC\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer as tf\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import auc, roc_curve\nfrom string import punctuation\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.calibration import CalibratedClassifierCV\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:52:28.075574Z","iopub.execute_input":"2024-02-08T09:52:28.076623Z","iopub.status.idle":"2024-02-08T09:52:31.520467Z","shell.execute_reply.started":"2024-02-08T09:52:28.076553Z","shell.execute_reply":"2024-02-08T09:52:31.519581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# read csv file","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sentiment-analysis-dataset/training.1600000.processed.noemoticon.csv', \n                 delimiter=',', encoding='ISO-8859-1')\ndf.columns = ['sentiment','id','date','query','user','text']\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:52:31.522457Z","iopub.execute_input":"2024-02-08T09:52:31.523275Z","iopub.status.idle":"2024-02-08T09:52:36.830799Z","shell.execute_reply.started":"2024-02-08T09:52:31.523239Z","shell.execute_reply":"2024-02-08T09:52:36.829816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:52:36.832581Z","iopub.execute_input":"2024-02-08T09:52:36.833422Z","iopub.status.idle":"2024-02-08T09:52:37.391629Z","shell.execute_reply.started":"2024-02-08T09:52:36.833381Z","shell.execute_reply":"2024-02-08T09:52:37.390293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:52:37.397865Z","iopub.execute_input":"2024-02-08T09:52:37.398324Z","iopub.status.idle":"2024-02-08T09:52:37.504298Z","shell.execute_reply.started":"2024-02-08T09:52:37.398286Z","shell.execute_reply":"2024-02-08T09:52:37.502924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:52:37.505932Z","iopub.execute_input":"2024-02-08T09:52:37.506488Z","iopub.status.idle":"2024-02-08T09:52:37.992006Z","shell.execute_reply.started":"2024-02-08T09:52:37.506451Z","shell.execute_reply":"2024-02-08T09:52:37.990535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['sentiment'] = df['sentiment'].replace({4:1})","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:52:37.995064Z","iopub.execute_input":"2024-02-08T09:52:37.995555Z","iopub.status.idle":"2024-02-08T09:52:38.016099Z","shell.execute_reply.started":"2024-02-08T09:52:37.995507Z","shell.execute_reply":"2024-02-08T09:52:38.014874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(style=\"whitegrid\") \n\nsns.countplot(data=df, x='sentiment', hue='sentiment', palette='Set2')\n\n# Customize plot labels and title if needed\nplt.xlabel('Sentiment')\nplt.ylabel('Count')\nplt.title('Distribution of Sentiments')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:52:38.017442Z","iopub.execute_input":"2024-02-08T09:52:38.017768Z","iopub.status.idle":"2024-02-08T09:52:38.627533Z","shell.execute_reply.started":"2024-02-08T09:52:38.017739Z","shell.execute_reply":"2024-02-08T09:52:38.626044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:52:38.629395Z","iopub.execute_input":"2024-02-08T09:52:38.629901Z","iopub.status.idle":"2024-02-08T09:52:38.766801Z","shell.execute_reply.started":"2024-02-08T09:52:38.629840Z","shell.execute_reply":"2024-02-08T09:52:38.765581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop_duplicates('text')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:52:38.768491Z","iopub.execute_input":"2024-02-08T09:52:38.769949Z","iopub.status.idle":"2024-02-08T09:52:39.289274Z","shell.execute_reply.started":"2024-02-08T09:52:38.769898Z","shell.execute_reply":"2024-02-08T09:52:39.287978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"\n\n\nstuff_to_be_removed = list(punctuation)\n\n\n\n\n\ndef textprocessing(text):\n    text = str(text)\n    text = text.lower()                                                          # converting all uppercase letters to lowercase\n    text = re.sub(r\"https\\S+|www\\S+|https\\S+\",\" \",text,flags=re.MULTILINE)       # removing all links from dataset\n    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)       \n    text = re.sub(r'\\@\\w+|\\#',\" \",text)                                          # removing # and @ symbols from dataset\n    text = re.sub(r'[^\\w\\s\\`]',\" \",text)                                         # removing other symbols like ^ except '\n    text_tokens = word_tokenize(text) \n    lem = SnowballStemmer(\"english\")\n    text = [lem.stem(word) for word in text_tokens if not word in stuff_to_be_removed] \n    text1 = \" \".join(text)\n    \n    return text1 ","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:52:39.296138Z","iopub.execute_input":"2024-02-08T09:52:39.297653Z","iopub.status.idle":"2024-02-08T09:52:39.306758Z","shell.execute_reply.started":"2024-02-08T09:52:39.297605Z","shell.execute_reply":"2024-02-08T09:52:39.305581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_cleaned = pd.DataFrame()\ndf['text'] = df['text'].apply(textprocessing)\ndf['text'].head()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:52:39.308296Z","iopub.execute_input":"2024-02-08T09:52:39.308907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"negative_text = ' '.join(df[df['sentiment'] == 0]['text'])\npositive_text = ' '.join(df[df['sentiment'] == 1]['text'])\ndf = df[['sentiment','text']]\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizations","metadata":{}},{"cell_type":"code","source":"wordcloud = WordCloud(width=800, height=400, background_color='black').generate(negative_text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud = WordCloud(width=800, height=400, background_color='black').generate(positive_text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Scaling","metadata":{}},{"cell_type":"code","source":"x = df['text']\ny = df['sentiment']\n\nvectorizer = tf()\nvectors = vectorizer.fit_transform(x)\n\n# ngrams reduce accuracy of the model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_train_svm, X_temp_svm, y_train_svm, y_temp_svm = train_test_split(vectors, y, test_size=0.3, random_state=52)\n\nX_validation_svm, X_test_svm, y_validation_svm, y_test_svm = train_test_split(X_temp_svm, y_temp_svm, test_size=0.5, random_state=52)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM with PCA","metadata":{}},{"cell_type":"code","source":"\n\n\nn_components = 100  \nsvd = TruncatedSVD(n_components=n_components)\nX_train_svm_pca = svd.fit_transform(X_train_svm)\nX_validation_svm_pca = svd.transform(X_validation_svm)\nX_test_svm_pca = svd.transform(X_test_svm)\n\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_model = LinearSVC(dual = True)\nsvm_model.fit(X_train_svm_pca, y_train_svm)\n\n\ny_pred_validation_svm = svm_model.predict(X_validation_svm_pca)\naccuracy_validation_svm = accuracy_score(y_validation_svm, y_pred_validation_svm)\nprint(f\"Accuracy on the validation set: {accuracy_validation_svm}\")\n\n\ny_pred_test_svm = svm_model.predict(X_test_svm_pca)\naccuracy_test_svm = accuracy_score(y_test_svm, y_pred_test_svm)\nprint(f\"Accuracy on the test set: {accuracy_test_svm}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n\n# # Define the parameter grid\n# param_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n#               'C': [0.1, 1, 10, 100]}  # You can adjust other hyperparameters as well\n\n# # Create a grid search\n# grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n\n# # Fit the grid search to the data\n# grid_search.fit(train_vectors, train_labels)\n\n# # Get the best parameters\n# best_params = grid_search.best_params_\n# print(f\"Best Parameters: {best_params}\")\n\n# # Get the best model\n# best_model = grid_search.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM without PCA","metadata":{}},{"cell_type":"code","source":"\n\nclassifier = CalibratedClassifierCV(LinearSVC(dual = True), method='sigmoid')\nclassifier.fit(X_train_svm, y_train_svm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_predictions_train = classifier.predict(X_train_svm)\n\naccuracy = accuracy_score(y_train_svm, svm_predictions_train)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n\nprint(\"Classification Report:\")\nprint(classification_report(y_train_svm, svm_predictions_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_prediction_test = classifier.predict(X_test_svm)\n\n\naccuracy = accuracy_score(y_test_svm, svm_prediction_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n\nprint(\"Classification Report:\")\nprint(classification_report(y_test_svm, svm_prediction_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_predictions_validation= classifier.predict(X_validation_svm)\n\naccuracy = accuracy_score(y_validation_svm, svm_predictions_validation)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n\nprint(\"Classification Report:\")\nprint(classification_report(y_validation_svm, svm_predictions_validation))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downsampling","metadata":{}},{"cell_type":"code","source":"## majority class 0\ndf_majority_knn = df[df['sentiment']==0]\n## minority class 1\ndf_minority_knn = df[df['sentiment']==1]\n\ndf_majority_downsampled_knn = resample(df_majority_knn, \n                                 replace=False,   \n                                 n_samples=len(df_minority_knn)//5,    \n                                 random_state=134)\n\ndf_minority_downsampled_knn = resample(df_minority_knn, \n                                 replace=False,   \n                                 n_samples=len(df_minority_knn)//5,    \n                                 random_state=134)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df_majority_downsampled_knn, df_minority_downsampled_knn])\n\nx = df['text']\ny = df['sentiment']\n\n\nvectorizer2 = tf()\nvectors = vectorizer2.fit_transform(x)\n\nvectors.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(style=\"whitegrid\") \n\nsns.countplot(data=df, x='sentiment', hue='sentiment', palette='Set2')\n\n# Customize plot labels and title if needed\nplt.xlabel('Sentiment')\nplt.ylabel('Count')\nplt.title('Distribution of Sentiments')\n\n# Show the plot\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_knn, X_temp_knn, y_train_knn, y_temp_knn = train_test_split(vectors, y, test_size=0.3, random_state=52)\n\nX_validation_knn, X_test_knn, y_validation_knn, y_test_knn = train_test_split(X_temp_knn, y_temp_knn, test_size=0.5, random_state=52)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KNN with PCA","metadata":{}},{"cell_type":"code","source":"\nn_components = 100  \nsvd = TruncatedSVD(n_components=n_components)\nX_train_knn_pca = svd.fit_transform(X_train_knn)\nX_validation_knn_pca = svd.transform(X_validation_knn)\nX_test_knn_pca = svd.transform(X_test_knn)\n\n\nknn_model = KNeighborsClassifier(n_neighbors=5) \nknn_model.fit(X_train_knn_pca, y_train_knn)\n\n\ny_pred_validation_knn = knn_model.predict(X_validation_knn_pca)\naccuracy_validation_knn = accuracy_score(y_validation_knn, y_pred_validation_knn)\nprint(f\"Accuracy on the validation set: {accuracy_validation_knn}\")\n\ny_pred_test_knn = knn_model.predict(X_test_knn_pca)\naccuracy_test_knn = accuracy_score(y_test_knn, y_pred_test_knn)\nprint(f\"Accuracy on the test set: {accuracy_test_knn}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = int(np.sqrt(len(x)))\nprint(l)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KNN without PCA","metadata":{}},{"cell_type":"code","source":"knn_classifier = KNeighborsClassifier(n_neighbors=l)  # You can experiment with different values of k\nknn_classifier.fit(X_train_knn, y_train_knn)\n\n\nknn_predictions_train =knn_classifier.predict(X_train_knn) \nknn_accuracy = accuracy_score(y_train_knn, knn_predictions_train)\nprint(f\"KNN Accuracy: {knn_accuracy:.2f}\")\nprint(\"KNN Classification Report:\")\nprint(classification_report(y_train_knn, knn_predictions_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_prediction_test = knn_classifier.predict(X_test_knn) \nknn_accuracy = accuracy_score(y_test_knn, knn_prediction_test)\nprint(f\"KNN Accuracy: {knn_accuracy:.2f}\")\nprint(\"KNN Classification Report:\")\nprint(classification_report(y_test_knn, knn_prediction_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_predictions_validation =knn_classifier.predict(X_validation_knn) \nknn_accuracy = accuracy_score(y_validation_knn, knn_predictions_validation)\nprint(f\"KNN Accuracy: {knn_accuracy:.2f}\")\nprint(\"KNN Classification Report:\")\n\nprint(classification_report(y_validation_knn, knn_predictions_validation))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def metrics(y_train, y_train_pred, y_test, y_test_pred):\n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n    cm_train = confusion_matrix(y_train, y_train_pred)\n    disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=None)\n    disp_train.plot(ax=axes[0], cmap='Blues', values_format='d')\n    axes[0].set_title('Training Confusion Matrix ')\n\n    \n    cm_test = confusion_matrix(y_test, y_test_pred)\n    disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=None)\n    disp_test.plot(ax=axes[1], cmap='Blues', values_format='d')\n    axes[1].set_title('Testing Confusion Matrix')\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM ACC","metadata":{}},{"cell_type":"code","source":"metrics(y_train_svm,svm_predictions_train ,y_test_svm,svm_prediction_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KNN ACC","metadata":{}},{"cell_type":"code","source":"metrics(y_train_knn,knn_predictions_train ,y_test_knn,knn_prediction_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ROC Curve of KNN, SVM","metadata":{}},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr, label, title):\n    plt.plot(fpr, tpr, label='{} (AUC = {:.2f})'.format(label, auc(fpr, tpr)))\n\n\nplt.figure(figsize=(10, 6))\n\n# KNN\nknn_probs = knn_classifier.predict_proba(X_test_knn)[:, 1]\nknn_fpr, knn_tpr, _ = roc_curve(y_test_knn, knn_probs)\nplot_roc_curve(knn_fpr, knn_tpr, 'KNN', 'ROC Curve - KNN')\n\n# SVM\nsvm_probs = classifier.predict_proba(X_test_svm)[:, 1]\nsvm_fpr, svm_tpr, _ = roc_curve(y_test_svm, svm_probs)\nplot_roc_curve(svm_fpr, svm_tpr, 'SVM', 'ROC Curve - SVM')\n\n# Plotting diagonal line for reference\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc='lower right')\n\n# Show the plot\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\n\n|Model|Training Accuracy|Testing Accuracy|Validation Accuracy\n|---|---|---|--|\n|SVM|91%|85%|85%|\n|KNN|75%|74%|74%|","metadata":{}},{"cell_type":"code","source":"new_text = \"i happy to hear that\"\nnew_text_vector = vectorizer.transform([new_text])\n\nprediction = classifier.predict(new_text_vector)\n\nif prediction[0] == 1:\n    print(\"positve user comment\")\nelse:\n    print(\"negative user comment\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}